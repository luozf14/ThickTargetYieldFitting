{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential cross section fitting using BRICK \n",
    "## $^{12}\\rm{C}(^{12}C, \\alpha_{0})^{20}\\rm{Ne}$ \n",
    "\n",
    "## Steps\n",
    "* Construct a Python object that enables the calling of AZURE2 with an arbitrary input vector $\\theta$.\n",
    "* Set up priors for each of the sampled parameters and a corresponding prior ($\\ln\\Pi$) function.\n",
    "* Construct a global function that reads a SRIM file, input energy, and return the -dE/dx.\n",
    "* Construct the yield function.\n",
    "* Set up a likelihood ($\\ln\\mathcal{L}$) function.\n",
    "* Construct a posterior ($\\ln\\mathcal{P}$) function from the likelihood and prior functions.\n",
    "* Prepare the MCMC walker and sample the posterior ($\\ln\\mathcal{P}$) function with emcee.\n",
    "* Preview the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import emcee\n",
    "import corner\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.integrate import quad, quadrature\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from brick.azr import AZR\n",
    "from multiprocess import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "* Construct a Python object that enables the calling of AZURE2 with an arbitrary input vector $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict processes to one thread only. Good for AZURE2\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "# Construct an object that calls AZURE2 and takes input 'a0.arz'\n",
    "azr = AZR('a0.arz')\n",
    "\n",
    "# How many parameters are going to be sampled?\n",
    "nd = azr.config.nd + 1\n",
    "print(f'There are {nd} sampled parameters.\\n')\n",
    "\n",
    "# Get the initial input parameters\n",
    "# theta0 = azr.config.get_input_values()\n",
    "\n",
    "# Read initial parameters from previously fitted results.\n",
    "theta0 = []\n",
    "theta0_mask = []\n",
    "# initial_params_file = \"best-emcee.txt\"\n",
    "# with open(initial_params_file, \"r\") as file:\n",
    "#     for line in file:\n",
    "#         # Split the line by \":\"\n",
    "#         parts = line.strip().split(\":\")\n",
    "#         # Extract the numeric expression (second part after \":\")\n",
    "#         expression = parts[1].strip()\n",
    "#         # Split the expression into terms\n",
    "#         # Example: \"9.07146 + 3.37034 - 3.77688\" becomes [\"9.07146\", \"3.37034\", \"3.77688\"]\n",
    "#         expression = expression.replace(\"+\", \" \").replace(\"-\", \" \").split()\n",
    "#         # Convert to floats\n",
    "#         base_value = float(expression[0])  # First number (base value)\n",
    "#         addition_value = float(expression[1])  # Second number (value after \"+\")\n",
    "#         subtraction_value = float(expression[2])  # Third number (value after \"-\")\n",
    "#         # Append the base value to column_2_list\n",
    "#         theta0.append(base_value)\n",
    "#         # Find the max between addition_value and subtraction_value\n",
    "#         theta0_mask.append(100.*max(addition_value, subtraction_value))\n",
    "\n",
    "for i in range(nd-1):\n",
    "    theta0.append(1000)\n",
    "theta0.append(1E10)\n",
    "\n",
    "print(f'The initial input parameters are:\\n {theta0}\\n')\n",
    "print(f'The initial input parameters width are:\\n {theta0_mask}\\n')\n",
    "\n",
    "# What labels have been assigned to those parameters?\n",
    "labels = azr.config.labels\n",
    "labels.append('$N_{v}$')\n",
    "print(f'The labels of the input parameters are:\\n {labels}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data files\n",
    "data_files_list = os.listdir('data/')\n",
    "data_files_list.sort()\n",
    "print(data_files_list)\n",
    "num_energies = len(data_files_list)\n",
    "energies = [float(filename.replace('.txt', '')) for filename in data_files_list]\n",
    "energies = np.array(energies)\n",
    "data = []\n",
    "angle_lab = []\n",
    "yield_lab = []\n",
    "yield_err = []\n",
    "for i in range(num_energies):\n",
    "    temp = np.loadtxt(\"data/\"+data_files_list[i])\n",
    "    temp[:,2]=temp[:,2]*1E-15 # Scale factor of the yield\n",
    "    temp[:,3]=temp[:,3]*1E-15 # Scale factor of the yield's error\n",
    "    data.append(temp)\n",
    "    angle_lab.append(temp[:,1])\n",
    "    yield_lab.append(temp[:,2])\n",
    "    yield_err.append(temp[:,3])\n",
    "num_angles = len(angle_lab[0])\n",
    "angle_lab = np.asarray(angle_lab, dtype='float32').T\n",
    "yield_lab = np.asarray(yield_lab, dtype='float32').T\n",
    "yield_err = np.asarray(yield_err, dtype='float32').T\n",
    "print('shape of yield_lab is', yield_lab.shape)\n",
    "\n",
    "# Take a look at the data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for i in range(num_energies):\n",
    "    ax.errorbar(angle_lab[:,i], yield_lab[:,i], yerr=yield_err[:,i], linestyle='', capsize=2, fmt=\"o\", label=data_files_list[i])\n",
    "    # ax.scatter(angle_lab[i], yield_lab[i])\n",
    "ax.legend()\n",
    "ax.set_xlim(100, 140)\n",
    "ax.set_xlabel(r'$\\theta$ (deg, lab)')\n",
    "ax.set_ylabel(r'Yields (arb. units)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "* Set up priors for each of the sampled parameters and a corresponding prior ($\\ln\\Pi$) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors = []\n",
    "# for i in range(nd-1):\n",
    "#    if (i == 0) or (i==4) or (i==8) or (i==12) or (i==16) or (i==20) or (i==25) or (i==30) or (i==35) or (i==40) or (i==45) or (i==50) or (i==55) or (i==60) or (i==65):\n",
    "#       priors.append(stats.norm(theta0[i], 0.1*theta0[i]/2.355))\n",
    "#    else:\n",
    "#       priors.append(stats.uniform(0, 1E5))\n",
    "# priors.append(stats.uniform(1E4,1E6))\n",
    "\n",
    "priors = []\n",
    "for i in range(len(theta0)-1):\n",
    "    priors.append(stats.uniform(0,1E6))\n",
    "    # priors.append(stats.norm(theta0[i], theta0_mask[i]))\n",
    "priors.append(stats.uniform(1E9,1E11))\n",
    "\n",
    "# mask = np.array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]) # Widths of the Gaussians can be different.\n",
    "# priors = [stats.norm(mu, abs(mu) * mask[i]) for i, mu in enumerate(theta0)]\n",
    "\n",
    "def lnPi(theta):\n",
    "    return np.sum([pi.logpdf(t) for (pi, t) in zip(priors, theta)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "* Construct a global function that reads a SRIM file, input energy, and return the -dE/dx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the SRIM table\n",
    "srim_file = 'srim/CarbonInCarbon.txt'\n",
    "srim_table = []\n",
    "with open(srim_file, 'r') as file:\n",
    "    for line in file:\n",
    "        cols = line.split()\n",
    "        srim_table.append((float(cols[0]), float(cols[1]))) # (MeV, MeV/mm)\n",
    "srim_table=np.array(srim_table)\n",
    "\n",
    "# Construct the interpolation\n",
    "srim_interp = interp1d(srim_table[:,0], srim_table[:,1],kind='cubic')\n",
    "# new_x = np.arange(0.1,50,0.1)\n",
    "# plt.figure()\n",
    "# plt.plot(srim_table[:,0], srim_table[:,1], 'o', label='SRIM table')\n",
    "# plt.plot(new_x, srim_interp(new_x), '-', label='Interpolated -dE/dX')\n",
    "# plt.xlabel('E (MeV)')\n",
    "# plt.ylabel('-dE/dx (MeV/mm)')\n",
    "# plt.title('Stopping power of carbon in carbon')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "* Construct the yield function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y_{\\rm lab}(\\theta_{\\rm lab}; E_0)=N_{V}\\int_{0}^{E_0}\\left[\\sigma_{\\rm lab}(\\theta_{\\rm lab}; E)/-\\frac{{\\rm d} E}{{\\rm d} x}\\right]{\\rm d} E$$\n",
    "\n",
    "where $\\sigma_{\\rm lab}(\\theta_{\\rm lab})=\\frac{(1+\\gamma^2+2\\gamma\\cos\\theta_{\\rm c})^{1.5}}{1+\\gamma\\cos\\theta_{\\rm c}}\\sigma_{\\rm c}(\\theta_{\\rm c})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert COM to Lab\n",
    "m_a = 12\n",
    "m_A = 12\n",
    "m_b = 4\n",
    "m_B = 20\n",
    "Q_value=4.62\n",
    "# gamma = np.sqrt((m_a*m_b)/(m_A*m_B)*(m_b+m_B)/(m_a+m_A)*E_COM[0]/(E_COM[0]+Q))\n",
    "def yield_angle(theta, angle_index):\n",
    "    output = azr.extrapolate(theta[:-1],[angle_index])[0]\n",
    "    energy_c = output[:,0]\n",
    "    angle_c = output[:,2]\n",
    "    sigma_c = output[:,3]\n",
    "    energy_l=(m_a+m_A)/m_A*energy_c\n",
    "    gamma_local = np.sqrt((m_a*m_b)/(m_A*m_B)*(m_b+m_B)/(m_a+m_A)*energy_c/(energy_c+Q_value))\n",
    "    sigma_l = (1+gamma_local**2.+2.*gamma_local*np.cos(angle_c/180.*np.pi))**(3./2.)/(1+gamma_local*np.cos(angle_c/180.*np.pi))*sigma_c\n",
    "    # a_l=np.arccos((gamma_local+np.cos(angle_c/180*np.pi))/np.sqrt(1+gamma_local**2+2*gamma_local*np.cos(angle_c/180*np.pi)))\n",
    "    sigma_interp = interp1d(energy_l, sigma_l, kind='linear')\n",
    "    def integrand(E):\n",
    "        return sigma_interp(E)/srim_interp(E)\n",
    "    res = np.zeros(num_energies)\n",
    "    res[0] = quad(integrand, 0.5, energies[0]*m_A/(m_a+m_A))[0] # Integrate from E = 0.5 to 4.4 MeV\n",
    "    for i in range(num_energies):\n",
    "        if(i==0):\n",
    "            continue\n",
    "        else:\n",
    "            res[i] = res[i-1]+quad(integrand, energies[i-1]*m_A/(m_a+m_A), energies[i]*m_A/(m_a+m_A))[0] # Integrate from E_{i-1} to E_{i}\n",
    "    return res * theta[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "* Set up a likelihood ($\\ln\\mathcal{L}$) function.\n",
    "\n",
    "We'll assume that the data are random draws from uncorrelated Gaussian distributions centered at the $R$-matrix predictions. So, we have\n",
    "$$\n",
    "\\mathcal{L} = \\prod_i \\frac{1}{\\sqrt{2\\pi}\\sigma_i} e^{-\\frac{1}{2}\\left(\\frac{y_i-\\mu_i}{\\sigma_i}\\right)^2}~,\n",
    "$$\n",
    "where $y_i$ and $\\sigma_i$ are the data points and uncertainties, respectively, and $\\mu_i$ is the physical model prediction.\n",
    "\n",
    "We work with $\\ln{\\mathcal{L}}$ to avoid the numerical difficulties of dealing with extremely small values. The product then becomes a sum,\n",
    "$$\n",
    "\\ln{\\mathcal{L}} = \\sum_i \\left[-\\ln{(\\sqrt{2\\pi}\\sigma_i)} - \\frac{1}{2}\\left(\\frac{y_i-\\mu_i}{\\sigma_i}\\right)^2\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnL(theta):\n",
    "    mu=[]\n",
    "    for i in range(num_angles):\n",
    "        mu.append(yield_angle(theta, i))\n",
    "    mu = np.array(mu, dtype='float32')\n",
    "    temp_sum = np.zeros(num_energies)\n",
    "    for i in range(num_energies):\n",
    "        if(energies[i] == 4.4):\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*yield_err[[8,13,14,16,19,21],i]) - 0.5*((yield_lab[[8,13,14,16,19,21],i] - mu[[8,13,14,16,19,21],i])/yield_err[[8,13,14,16,19,21],i])**2)\n",
    "        elif(energies[i] == 4.6):\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*yield_err[[1,2,12,14,15,16,19,20,21,22],i]) - 0.5*((yield_lab[[1,2,12,14,15,16,19,20,21,22],i] - mu[[1,2,12,14,15,16,19,20,21,22],i])/yield_err[[1,2,12,14,15,16,19,20,21,22],i])**2)\n",
    "        elif(energies[i] == 4.7):\n",
    "            exclude_rows = [9,23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 5.0):\n",
    "            exclude_rows = [23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 5.1):\n",
    "            exclude_rows = [23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 5.5):\n",
    "            exclude_rows = [22,23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 5.7):\n",
    "            exclude_rows = [23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 5.8):\n",
    "            exclude_rows = [23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 6.0):\n",
    "            exclude_rows = [0]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 6.4):\n",
    "            exclude_rows = [23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 6.6):\n",
    "            exclude_rows = [23]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        elif(energies[i] == 7.4):\n",
    "            exclude_rows = [0]\n",
    "            temp_yield_err = np.delete(yield_err, exclude_rows, axis=0)\n",
    "            temp_yield_lab = np.delete(yield_lab, exclude_rows, axis=0)\n",
    "            temp_mu = np.delete(mu, exclude_rows, axis=0)\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*temp_yield_err[:,i]) - 0.5*((temp_yield_lab[:,i] - temp_mu[:,i])/temp_yield_err[:,i])**2)\n",
    "        else:\n",
    "            temp_sum[i]=np.sum(-np.log(np.sqrt(2*np.pi)*yield_err[:,i]) - 0.5*((yield_lab[:,i] - mu[:,i])/yield_err[:,i])**2)\n",
    "    return np.sum(temp_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "* Construct a posterior ($\\ln\\mathcal{P}$) function from the likelihood and prior functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnP(theta):\n",
    "    lnpi = lnPi( theta )                        # Calculate the prior\n",
    "    if not np.isfinite( lnpi ): \n",
    "        return -np.inf  # If the prior is not finite, return -inf\n",
    "    lnl = lnL( theta )                          # Calculate the likelihood\n",
    "    return lnl + lnpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "* Prepare the MCMC walker and sample the posterior ($\\ln\\mathcal{P}$) function with emcee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nw = 2 * nd  # number of walkers = 2 * number of sampled parameters\n",
    "\n",
    "# Each walker needs its own starting position. We'll take normally distributed\n",
    "# random values centered at theta0.\n",
    "p0 = np.zeros((nw, nd))\n",
    "# mask = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]) # Widths of the Gaussians can be different.\n",
    "mask = np.zeros(nd)\n",
    "for i in range(nd):\n",
    "    mask[i] = 0.01\n",
    "for i in range(nw):\n",
    "    mu = theta0\n",
    "    sig = np.abs(theta0) * mask\n",
    "    p0[i, :] = stats.norm(mu, sig).rvs()\n",
    "\n",
    "\n",
    "# We'll store the chain in chain.h5. (See emcee Backends documentation.)\n",
    "backend = emcee.backends.HDFBackend(\"chain.h5\")\n",
    "backend.reset(nw, nd)\n",
    "\n",
    "nsteps = 4000  # How many saved steps should each walker make?\n",
    "nthin = 1  # How often should the walkr save a step? n_total = nsteps * nthin\n",
    "nprocs = nw  # How many Python processes do you want to allocate?\n",
    "\n",
    "# For a stretch move\n",
    "move = emcee.moves.StretchMove()\n",
    "\n",
    "# emcee allows the user to specify the way the ensemble generates proposals.\n",
    "with Pool(processes=24) as pool:\n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        nw, nd, lnP, pool=pool, backend=backend, moves=[move]\n",
    "    )\n",
    "    state = sampler.run_mcmc(p0, nsteps, thin_by=nthin, progress=True, tune=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Posterior function evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the probability\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "lnp = backend.get_log_prob(discard=100)\n",
    "ax.plot(lnp)\n",
    "\n",
    "ax.set_xlabel('Step')\n",
    "ax.set_ylabel('ln( P )')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Parameters evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the samples\n",
    "nb=3950 # discard the first nb samples\n",
    "flat_samples = sampler.get_chain(flat=True, discard=nb)\n",
    "\n",
    "# Plot the parameters\n",
    "fig, ax = plt.subplots( int(nd / 2)+1, 2, figsize=( 15, 30 ) )\n",
    "\n",
    "means, lows, highs = [], [], []\n",
    "final_results = np.zeros(nd)\n",
    "for i in range( nd ):\n",
    "\n",
    "        mean = np.percentile( flat_samples[:,i], 50 )\n",
    "        low = np.percentile( flat_samples[:,i], 16 )\n",
    "        high = np.percentile( flat_samples[:,i], 84 )\n",
    "    \n",
    "        ax[i//2, i%2].set_title( labels[i] )\n",
    "        ax[i//2, i%2].set_xlabel( \"Step\" )\n",
    "\n",
    "        ax[i//2, i%2].plot( flat_samples[:,i], color=\"tab:blue\" )\n",
    "        ax[i//2, i%2].axhline( mean, color=\"tab:red\", linestyle=\"-\", lw=4 )\n",
    "        ax[i//2, i%2].axhline( low, color=\"tab:red\", linestyle=\"--\", lw=2 )\n",
    "        ax[i//2, i%2].axhline( high, color=\"tab:red\", linestyle=\"--\", lw=2 )\n",
    "\n",
    "        ax[i//2, i%2].set_ylabel( \"Value\" )\n",
    "\n",
    "        means.append( mean )\n",
    "        lows.append( low )\n",
    "        highs.append( high )\n",
    "\n",
    "# Save parameters to file\n",
    "with open( \"results/best-emcee.txt\", \"w\" ) as f:\n",
    "    for i in range( nd ):\n",
    "        f.write( f\"{azr.config.labels[i]}: {means[i]:.5f} + {highs[i]-means[i]:.5f} - {means[i]-lows[i]:.5f}\\n\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Corner plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = corner.corner(\n",
    "#     flat_samples, labels=labels, truths=means, quantiles=[0.16, 0.5, 0.84], title_fmt=\".4f\", fill_contours=True,\n",
    "#     show_titles=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_factor(theta):\n",
    "    output = np.array(azr.extrapolate(theta[:-1],[25])[0])\n",
    "    s_factor_output = np.array([output[:,0], output[:,1], output[:,3], output[:,4]])\n",
    "    return s_factor_output\n",
    "\n",
    "def yield_angles(theta):\n",
    "    mu=[]\n",
    "    for i in range(num_angles):\n",
    "        mu.append(yield_angle(theta, i))\n",
    "    mu = np.array(mu, dtype='float32')\n",
    "    return mu\n",
    "\n",
    "def process_parallel():\n",
    "    # Shuffle and take last 100 samples\n",
    "    np.random.shuffle(flat_samples)\n",
    "    samples_to_process = flat_samples[-1000:]\n",
    "    \n",
    "    # Create a pool of workers\n",
    "    with Pool(processes=24) as pool:\n",
    "        # Map the function to the samples and show progress\n",
    "        buckets_s_factor = list(tqdm(\n",
    "            pool.imap(s_factor, samples_to_process),\n",
    "            total=len(samples_to_process)\n",
    "        ))\n",
    "        buckets_yield_angles = list(tqdm(\n",
    "            pool.imap(yield_angles, samples_to_process),\n",
    "            total=len(samples_to_process)\n",
    "        ))\n",
    "    \n",
    "    return buckets_s_factor, buckets_yield_angles\n",
    "buckets_s_factor, buckets_yield_angles = process_parallel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reampled results and compared it to the data\n",
    "buckets_s_factor=np.array(buckets_s_factor)\n",
    "\n",
    "mean = np.percentile(buckets_s_factor, 50, axis=0 ).T\n",
    "low = np.percentile(buckets_s_factor, 16, axis=0).T\n",
    "high = np.percentile(buckets_s_factor, 84, axis=0).T\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=( 15, 5 ))\n",
    "ax[0].set_xlim(13, 20)\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xlabel(r'Excitation energy (MeV, COM)')\n",
    "ax[0].set_ylabel(r'Cross section (barn)')\n",
    "ax[0].plot(mean[20:,1], mean[20:,2], label=\"Extrapolation\", color=\"red\")\n",
    "ax[0].fill_between(mean[20:,1], low[20:,2], high[20:,2], color=\"red\", alpha=0.5 )\n",
    "\n",
    "ax[1].set_xlim(0, 5)\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_xlabel(r'Ecm (MeV, COM)')\n",
    "ax[1].set_ylabel(r'S-factor (MeV b)')\n",
    "ax[1].plot(mean[:,0], mean[:,3], label=\"Extrapolation\", color=\"red\")\n",
    "ax[1].fill_between(mean[:,0], low[:,3], high[:,3], color=\"red\", alpha=0.5 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets_yield_angles=np.array(buckets_yield_angles)\n",
    "\n",
    "mean = np.percentile(buckets_yield_angles, 50, axis=0 )\n",
    "low = np.percentile(buckets_yield_angles, 16, axis=0)\n",
    "high = np.percentile(buckets_yield_angles, 84, axis=0)\n",
    "\n",
    "fig, ax = plt.subplots( int(num_energies / 2)+1, 2, figsize=( 15, 50 ) )\n",
    "for i in range( num_energies ):\n",
    "        ax[i//2, i%2].set_xlabel( \"Angle (deg, lab)\" )\n",
    "        ax[i//2, i%2].set_ylabel( \"Yield (arb. unit)\" )\n",
    "\n",
    "        mask = yield_err[:, i] > 0\n",
    "        ax[i//2, i%2].errorbar(angle_lab[mask, i], yield_lab[mask, i], yerr=yield_err[mask, i], linestyle='', capsize=2, fmt=\"o\", label=data_files_list[i])\n",
    "        ax[i//2, i%2].legend()\n",
    "\n",
    "        ax[i//2, i%2].plot(angle_lab[mask, i], mean[mask, i], marker=\"o\", label=\"Extrapolation\", color=\"red\")\n",
    "        ax[i//2, i%2].fill_between(angle_lab[mask, i], low[mask, i], high[mask, i], color=\"red\", alpha=0.5 )\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
